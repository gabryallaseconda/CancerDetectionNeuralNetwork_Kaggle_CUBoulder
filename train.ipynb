{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Training process of the final model with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tools import *\n",
    "\n",
    "def write_log(logfile, train_loss, test_loss, test_score, lr):\n",
    "    with open(logfile, \"a+\") as log:\n",
    "        log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, test_loss, test_score, lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing label dataset\n",
    "\n",
    "To run the full crossvalidation, remove .head(30000). This will multiply about by 20 the time required by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOLDERS PATH\n",
    "source_dir = 'histopathologic-cancer-detection/'\n",
    "train_im_source_dir = source_dir+'/train'\n",
    "\n",
    "# IMPORTING DATA\n",
    "train_data = pd.read_csv(os.path.join(source_dir,'train_labels.csv')) \n",
    "train_data = train_data.sample(frac=1, random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = list(train_data.id)\n",
    "data_labels = list(train_data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging directories\n",
    "model_source_dir = 'trained_model/'\n",
    "model_name = 'final'\n",
    "\n",
    "# Batch size\n",
    "b_size = 96 # batch size\n",
    "\n",
    "# Epochs\n",
    "n_epochs = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - loop on cv folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting log files\n",
    "logfile =  model_source_dir+'/{}.logfile.txt'.format(model_name)\n",
    "best_w_path = model_source_dir+'/{}.best.pt'.format(model_name)\n",
    "model_path =  model_source_dir+'/{}.model.pt'.format(model_name)\n",
    "    \n",
    "# Data augmentation functions\n",
    "training_aug = aug_train() \n",
    "    \n",
    "# Learning Rate setting. This will be modified according to cyclic scheduler\n",
    "curr_lr = 3e-3 \n",
    "    \n",
    "# Loader for the training and the validation\n",
    "train_loader = torch.utils.data.DataLoader(DataGenerator(\n",
    "                                                data_ids,\n",
    "                                                data_labels,\n",
    "                                                training_aug, \n",
    "                                                train_im_source_dir),\n",
    "                                            pin_memory=False,\n",
    "                                            num_workers=4,\n",
    "                                            batch_size=b_size) \n",
    "                                            \n",
    "# Loss function \n",
    "loss_f = nn.BCELoss() # BINARY CROSS ENTROPY\n",
    "\n",
    "# Import pretrained model\n",
    "base_model = pretrainedmodels.resnet34(num_classes=1000, \n",
    "                                           pretrained='imagenet').to(device) \n",
    "    \n",
    "# Shape the model    \n",
    "model = Net(base_model, 512).to(device)\n",
    "\n",
    "# Optimizer\n",
    "# Some layers are freezed for the first iteration, by setting the learning rate to zero\n",
    "optimizer = optim.SGD([{'params': model.layer0.parameters(), 'lr': 0},\n",
    "                        {'params': model.layer2.parameters(), 'lr': 0},\n",
    "                        {'params': model.layer1.parameters(), 'lr': 0},\n",
    "                        {'params': model.layer3.parameters(), 'lr': 0},\n",
    "                        {'params': model.layer4.parameters(), 'lr': 0},\n",
    "                        {'params': model.classif.parameters()}], lr=0.05, momentum=0.9)\n",
    "    \n",
    "# First Training procedure\n",
    "train_loss = train(model= model,\n",
    "                    train_loader= train_loader, \n",
    "                    optimizer= optimizer, \n",
    "                    epoch= 0, \n",
    "                    log_interval= 100, \n",
    "                    loss_f= loss_f, \n",
    "                    scheduler= None,\n",
    "                    device=device)\n",
    "    \n",
    "    \n",
    "# Loop on epochs\n",
    "\n",
    "# Values to monitor the loss trough the loop on epochs\n",
    "best_score = 0\n",
    "best_loss = 1e5\n",
    "idx_stop = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Print current epoch\n",
    "    print(f'Begin of epoch {epoch}')\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
    "\n",
    "    # Scheduler for triangular cyclic learning rate\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=curr_lr, max_lr=3*curr_lr, mode = 'triangular')\n",
    "\n",
    "    # Train procedure\n",
    "    train_loss = train(model= model,\n",
    "                    train_loader= train_loader, \n",
    "                    optimizer= optimizer, \n",
    "                    epoch= epoch, \n",
    "                    log_interval= 1000, \n",
    "                    loss_f= loss_f, \n",
    "                    scheduler= scheduler,\n",
    "                    device = device)\n",
    "    \n",
    "    print('\\t end epoch - loss: {:.6f}'.format(train_loss))\n",
    "        \n",
    "        \n",
    "    \n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-networks-_F4AaA2c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
