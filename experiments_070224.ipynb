{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    130908\n",
       "1     89117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"histopathologic-cancer-detection/train_labels.csv\")\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.468945319074924"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "130908/89117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset has 220025 rows\n",
      "Splitted has in total 220025 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_dataframe(df:pd.DataFrame, num_of_splits:int) -> list[pd.DataFrame]:\n",
    "\n",
    "    # Shuffle the rows\n",
    "    df_shuffled = df.sample(frac=1, random_state=10) \n",
    "\n",
    "    rows_per_split = len(df_shuffled) // num_of_splits\n",
    "\n",
    "    dfs = [df_shuffled.iloc[i * rows_per_split:(i + 1) * rows_per_split] for i in range(num_of_splits)]\n",
    "\n",
    "    # Print to check line losses\n",
    "    print(f'Original dataset has {len(df)} rows')\n",
    "    print(f'Splitted has in total {sum([len(part) for part in dfs])} rows')\n",
    "\n",
    "    return dfs\n",
    "\n",
    "dfs = split_dataframe(df = df, num_of_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "#from torch.autograd import Variable\n",
    "#from torch.optim import Optimizer\n",
    "#from torch.utils import data\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "#import cv2\n",
    "from skimage.io import imread\n",
    "#from torch.utils.data.sampler import WeightedRandomSampler, BatchSampler\n",
    "#from tqdm import tqdm\n",
    "#from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold\n",
    "#import pretrainedmodels.utils as utils\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "from tools import *\n",
    "\n",
    "def write_log(logfile, train_loss, test_loss, test_score, lr):\n",
    "    with open(logfile, \"a+\") as log:\n",
    "        log.write(\"{}\\t{}\\t{}\\t{}\\n\".format(train_loss, test_loss, test_score, lr))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PER IMPOSTARE IL DEVICE\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('MPS is available')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No acceleration available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# FOLDERS PATH\n",
    "DIR = 'histopathologic-cancer-detection/'\n",
    "train_im_dir = DIR+'/train'\n",
    "test_im_dir = DIR+'/test'\n",
    "\n",
    "# IMPORTING DATA\n",
    "train_data = pd.read_csv(os.path.join(DIR,'train_labels.csv')) #labels for train data\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "# model_dir = os.path.join(DIR, 'resnet34')\n",
    "# model_name = 'resnet34'\n",
    "model_dir = 'this_model/'#os.path.join(DIR, 'this_model')\n",
    "model_name = 'this_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_groups = 15 # number of folds # CROSS-VALIDATION PER VALIDAZIONE\n",
    "b_size = 96 # batch size\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION K-FOLD \n",
    "skf = StratifiedKFold(n_splits=n_groups)\n",
    "\n",
    "# CONTENITORI PER RACCOGLIERE I DATI DELLA CROSS-VALIDATION\n",
    "folds_id_train = []\n",
    "folds_label_train = []\n",
    "folds_id_val = []\n",
    "folds_label_val = []\n",
    "\n",
    "# RIEMPIO I CONTENITORI PER LA CROSS-VALIDATION\n",
    "for train_index, test_index in skf.split(train_data['id'].values, train_data['label'].values):\n",
    "    # Train\n",
    "    folds_id_train.append(train_data['id'].values[train_index])\n",
    "    folds_label_train.append(train_data['label'].values[train_index])\n",
    "    # Validation\n",
    "    folds_id_val.append(train_data['id'].values[test_index])    \n",
    "    folds_label_val.append(train_data['label'].values[test_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_samples(dataset, n, etichetta):\n",
    "    label_matching_indexes = dataset.index[dataset['label'] == etichetta].tolist()\n",
    "    label_matching_indexes = label_matching_indexes[:n]\n",
    "    return dataset.loc[label_matching_indexes], dataset.drop(index=label_matching_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validataion_proportion = 0.1\n",
    "train_proportion = 1-validataion_proportion\n",
    "\n",
    "# Get number of elements for each class\n",
    "zeros = len(train_data[train_data.label == 0])\n",
    "ones = len(train_data[train_data.label == 1])\n",
    "\n",
    "# Get the proportion of elements for training, splitted for each class\n",
    "train_zeros = int(zeros/n_groups*0.9)\n",
    "train_ones = int(ones/n_groups*0.9)\n",
    "\n",
    "# Get the proportion of elements for training, splitted for each class\n",
    "val_zeros = int(zeros/n_groups*0.1)\n",
    "val_ones = int(ones/n_groups*0.1)\n",
    "\n",
    "# Shuffle the training data, get df dataset\n",
    "df = train_data.sample(frac=1, random_state=10)\n",
    "\n",
    "# Initializate empty lists\n",
    "folds_id_train = []\n",
    "folds_label_train = []\n",
    "folds_id_val = []\n",
    "folds_label_val = []\n",
    "\n",
    "# Loop on elements for validation\n",
    "for i in range(n_groups):\n",
    "\n",
    "    #print('---')\n",
    "    #print(len(df))\n",
    "    \n",
    "    # Get first elements in df, return also df without elements\n",
    "    fold_train_zeros, df = get_samples(df, train_zeros, 0)\n",
    "    #print(len(df))\n",
    "    fold_train_ones, df = get_samples(df, train_ones, 1)\n",
    "    #print(len(df))\n",
    "\n",
    "    # Merge zero and ones together\n",
    "    fold_train = pd.concat([fold_train_zeros, fold_train_ones], ignore_index=True).sample(frac=1, random_state=10+n_groups)\n",
    "\n",
    "    \n",
    "    folds_id_train.append(fold_train['id'].values)\n",
    "    folds_label_train .append(fold_train['label'].values)\n",
    "\n",
    "\n",
    "    fold_val_zeros, df = get_samples(df, val_zeros, 0)\n",
    "    #print(len(df))\n",
    "    fold_val_ones, df = get_samples(df, val_ones, 1)\n",
    "    #print(len(df))\n",
    "\n",
    "    fold_val = pd.concat([fold_val_zeros, fold_val_ones], ignore_index=True).sample(frac=1, random_state=10+n_groups)\n",
    "\n",
    "    folds_id_val.append(fold_val['id'].values)    \n",
    "    folds_label_val.append(fold_val['label'].values)\n",
    "\n",
    "    #print(fold_train.head())\n",
    "    #print(fold_val.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.703969\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.583996\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.515575\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.509344\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.510155\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.497415\n",
      "Mean train loss on epoch 0 : 0.5534087651471297\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.474496, roc auc: 0.8538\n",
      "\n",
      "we are in epoch 0\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.445296\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.343132\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.227121\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.176492\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.139942\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.111537\n",
      "Mean train loss on epoch 0 : 0.24058662698293728\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.377712, roc auc: 0.9604\n",
      "\n",
      "Test loss improved from 100000.0 to 0.3777122087776661, saving\n",
      "we are in epoch 1\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 1 [0/50000 (0.000%)]\tLoss: 0.076288\n",
      "Train Epoch: 1 [9600/50000 (19.200%)]\tLoss: 0.092917\n",
      "Train Epoch: 1 [19200/50000 (38.400%)]\tLoss: 0.083591\n",
      "Train Epoch: 1 [28800/50000 (57.600%)]\tLoss: 0.066769\n",
      "Train Epoch: 1 [38400/50000 (76.800%)]\tLoss: 0.062425\n",
      "Train Epoch: 1 [48000/50000 (96.000%)]\tLoss: 0.059461\n",
      "Mean train loss on epoch 1 : 0.07357502089347691\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.413329, roc auc: 0.9610\n",
      "\n",
      "Loss 0.41332932841032743, did not improve from 0.3777122087776661 for 0 epochs\n",
      "we are in epoch 2\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 2 [0/50000 (0.000%)]\tLoss: 0.046764\n",
      "Train Epoch: 2 [9600/50000 (19.200%)]\tLoss: 0.051259\n",
      "Train Epoch: 2 [19200/50000 (38.400%)]\tLoss: 0.040352\n",
      "Train Epoch: 2 [28800/50000 (57.600%)]\tLoss: 0.035809\n",
      "Train Epoch: 2 [38400/50000 (76.800%)]\tLoss: 0.039590\n",
      "Train Epoch: 2 [48000/50000 (96.000%)]\tLoss: 0.035548\n",
      "Mean train loss on epoch 2 : 0.04155347629857715\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.506190, roc auc: 0.9628\n",
      "\n",
      "Loss 0.5061897467821836, did not improve from 0.3777122087776661 for 1 epochs\n",
      "we are in epoch 3\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 3 [0/50000 (0.000%)]\tLoss: 0.022374\n",
      "Train Epoch: 3 [9600/50000 (19.200%)]\tLoss: 0.029166\n",
      "Train Epoch: 3 [19200/50000 (38.400%)]\tLoss: 0.033842\n",
      "Train Epoch: 3 [28800/50000 (57.600%)]\tLoss: 0.025108\n",
      "Train Epoch: 3 [38400/50000 (76.800%)]\tLoss: 0.029162\n",
      "Train Epoch: 3 [48000/50000 (96.000%)]\tLoss: 0.024461\n",
      "Mean train loss on epoch 3 : 0.02735212848735197\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.577096, roc auc: 0.9601\n",
      "\n",
      "Loss 0.5770963588729501, did not improve from 0.3777122087776661 for 2 epochs\n",
      "we are in epoch 4\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 4 [0/50000 (0.000%)]\tLoss: 0.074853\n",
      "Train Epoch: 4 [9600/50000 (19.200%)]\tLoss: 0.020502\n",
      "Train Epoch: 4 [19200/50000 (38.400%)]\tLoss: 0.019092\n",
      "Train Epoch: 4 [28800/50000 (57.600%)]\tLoss: 0.022890\n",
      "Train Epoch: 4 [38400/50000 (76.800%)]\tLoss: 0.019845\n",
      "Train Epoch: 4 [48000/50000 (96.000%)]\tLoss: 0.016790\n",
      "Mean train loss on epoch 4 : 0.028995254140366643\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.467778, roc auc: 0.9679\n",
      "\n",
      "Loss 0.46777752321213484, did not improve from 0.3777122087776661 for 3 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 5\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 5 [0/50000 (0.000%)]\tLoss: 0.132729\n",
      "Train Epoch: 5 [9600/50000 (19.200%)]\tLoss: 0.076403\n",
      "Train Epoch: 5 [19200/50000 (38.400%)]\tLoss: 0.070992\n",
      "Train Epoch: 5 [28800/50000 (57.600%)]\tLoss: 0.059399\n",
      "Train Epoch: 5 [38400/50000 (76.800%)]\tLoss: 0.051135\n",
      "Train Epoch: 5 [48000/50000 (96.000%)]\tLoss: 0.048857\n",
      "Mean train loss on epoch 5 : 0.0732525583341097\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.433515, roc auc: 0.9585\n",
      "\n",
      "Loss 0.4335148432292044, did not improve from 0.3777122087776661 for 4 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 6\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 6 [0/50000 (0.000%)]\tLoss: 0.067921\n",
      "Train Epoch: 6 [9600/50000 (19.200%)]\tLoss: 0.075579\n",
      "Train Epoch: 6 [19200/50000 (38.400%)]\tLoss: 0.066755\n",
      "Train Epoch: 6 [28800/50000 (57.600%)]\tLoss: 0.058128\n",
      "Train Epoch: 6 [38400/50000 (76.800%)]\tLoss: 0.061732\n",
      "Train Epoch: 6 [48000/50000 (96.000%)]\tLoss: 0.049074\n",
      "Mean train loss on epoch 6 : 0.06319819478706146\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.391437, roc auc: 0.9647\n",
      "\n",
      "Loss 0.39143717428669333, did not improve from 0.3777122087776661 for 5 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 7\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 7 [0/50000 (0.000%)]\tLoss: 0.075457\n",
      "Train Epoch: 7 [9600/50000 (19.200%)]\tLoss: 0.077777\n",
      "Train Epoch: 7 [19200/50000 (38.400%)]\tLoss: 0.068935\n",
      "Train Epoch: 7 [28800/50000 (57.600%)]\tLoss: 0.061535\n",
      "Train Epoch: 7 [38400/50000 (76.800%)]\tLoss: 0.056933\n",
      "Train Epoch: 7 [48000/50000 (96.000%)]\tLoss: 0.054367\n",
      "Mean train loss on epoch 7 : 0.06583398395062735\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.387004, roc auc: 0.9612\n",
      "\n",
      "Loss 0.38700372679159045, did not improve from 0.3777122087776661 for 6 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 8\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 8 [0/50000 (0.000%)]\tLoss: 0.085140\n",
      "Train Epoch: 8 [9600/50000 (19.200%)]\tLoss: 0.082663\n",
      "Train Epoch: 8 [19200/50000 (38.400%)]\tLoss: 0.077474\n",
      "Train Epoch: 8 [28800/50000 (57.600%)]\tLoss: 0.074019\n",
      "Train Epoch: 8 [38400/50000 (76.800%)]\tLoss: 0.059947\n",
      "Train Epoch: 8 [48000/50000 (96.000%)]\tLoss: 0.062475\n",
      "Mean train loss on epoch 8 : 0.07361967242012422\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.364500, roc auc: 0.9640\n",
      "\n",
      "Test loss improved from 0.3777122087776661 to 0.36450035823509097, saving\n",
      "we are in epoch 9\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 9 [0/50000 (0.000%)]\tLoss: 0.040717\n",
      "Train Epoch: 9 [9600/50000 (19.200%)]\tLoss: 0.059570\n",
      "Train Epoch: 9 [19200/50000 (38.400%)]\tLoss: 0.061324\n",
      "Train Epoch: 9 [28800/50000 (57.600%)]\tLoss: 0.057292\n",
      "Train Epoch: 9 [38400/50000 (76.800%)]\tLoss: 0.061663\n",
      "Train Epoch: 9 [48000/50000 (96.000%)]\tLoss: 0.054367\n",
      "Mean train loss on epoch 9 : 0.05582213803116853\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.368878, roc auc: 0.9641\n",
      "\n",
      "Loss 0.36887799738906324, did not improve from 0.36450035823509097 for 0 epochs\n",
      "we are in epoch 10\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 10 [0/50000 (0.000%)]\tLoss: 0.108650\n",
      "Train Epoch: 10 [9600/50000 (19.200%)]\tLoss: 0.057884\n",
      "Train Epoch: 10 [19200/50000 (38.400%)]\tLoss: 0.049694\n",
      "Train Epoch: 10 [28800/50000 (57.600%)]\tLoss: 0.057384\n",
      "Train Epoch: 10 [38400/50000 (76.800%)]\tLoss: 0.043295\n",
      "Train Epoch: 10 [48000/50000 (96.000%)]\tLoss: 0.044721\n",
      "Mean train loss on epoch 10 : 0.06027133822441102\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.386318, roc auc: 0.9628\n",
      "\n",
      "Loss 0.38631768384948373, did not improve from 0.36450035823509097 for 1 epochs\n",
      "we are in epoch 11\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 11 [0/50000 (0.000%)]\tLoss: 0.048954\n",
      "Train Epoch: 11 [9600/50000 (19.200%)]\tLoss: 0.050779\n",
      "Train Epoch: 11 [19200/50000 (38.400%)]\tLoss: 0.043216\n",
      "Train Epoch: 11 [28800/50000 (57.600%)]\tLoss: 0.045828\n",
      "Train Epoch: 11 [38400/50000 (76.800%)]\tLoss: 0.037994\n",
      "Train Epoch: 11 [48000/50000 (96.000%)]\tLoss: 0.044673\n",
      "Mean train loss on epoch 11 : 0.04524068256335643\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.387009, roc auc: 0.9643\n",
      "\n",
      "Loss 0.3870090330019593, did not improve from 0.36450035823509097 for 2 epochs\n",
      "we are in epoch 12\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 12 [0/50000 (0.000%)]\tLoss: 0.059797\n",
      "Train Epoch: 12 [9600/50000 (19.200%)]\tLoss: 0.040263\n",
      "Train Epoch: 12 [19200/50000 (38.400%)]\tLoss: 0.038869\n",
      "Train Epoch: 12 [28800/50000 (57.600%)]\tLoss: 0.040540\n",
      "Train Epoch: 12 [38400/50000 (76.800%)]\tLoss: 0.039570\n",
      "Train Epoch: 12 [48000/50000 (96.000%)]\tLoss: 0.038510\n",
      "Mean train loss on epoch 12 : 0.042924861266122515\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.402994, roc auc: 0.9640\n",
      "\n",
      "Loss 0.40299445088021457, did not improve from 0.36450035823509097 for 3 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 13\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 13 [0/50000 (0.000%)]\tLoss: 0.079670\n",
      "Train Epoch: 13 [9600/50000 (19.200%)]\tLoss: 0.060740\n",
      "Train Epoch: 13 [19200/50000 (38.400%)]\tLoss: 0.058582\n",
      "Train Epoch: 13 [28800/50000 (57.600%)]\tLoss: 0.064956\n",
      "Train Epoch: 13 [38400/50000 (76.800%)]\tLoss: 0.063362\n",
      "Train Epoch: 13 [48000/50000 (96.000%)]\tLoss: 0.058167\n",
      "Mean train loss on epoch 13 : 0.06424616570429255\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.360846, roc auc: 0.9653\n",
      "\n",
      "Test loss improved from 0.36450035823509097 to 0.3608460444957018, saving\n",
      "we are in epoch 14\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 14 [0/50000 (0.000%)]\tLoss: 0.048497\n",
      "Train Epoch: 14 [9600/50000 (19.200%)]\tLoss: 0.056258\n",
      "Train Epoch: 14 [19200/50000 (38.400%)]\tLoss: 0.056336\n",
      "Train Epoch: 14 [28800/50000 (57.600%)]\tLoss: 0.050732\n",
      "Train Epoch: 14 [38400/50000 (76.800%)]\tLoss: 0.051653\n",
      "Train Epoch: 14 [48000/50000 (96.000%)]\tLoss: 0.059848\n",
      "Mean train loss on epoch 14 : 0.0538875176361762\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.370998, roc auc: 0.9654\n",
      "\n",
      "Loss 0.37099847523495555, did not improve from 0.3608460444957018 for 0 epochs\n",
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.728510\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.567084\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.498654\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.475683\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.481096\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.467790\n",
      "Mean train loss on epoch 0 : 0.5364695736765861\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.467883, roc auc: 0.8573\n",
      "\n",
      "we are in epoch 0\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.384994\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.323609\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.235042\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.181332\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.143821\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.124408\n",
      "Mean train loss on epoch 0 : 0.23220080010592933\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.277977, roc auc: 0.9666\n",
      "\n",
      "Test loss improved from 100000.0 to 0.2779768304899335, saving\n",
      "we are in epoch 1\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 1 [0/50000 (0.000%)]\tLoss: 0.085801\n",
      "Train Epoch: 1 [9600/50000 (19.200%)]\tLoss: 0.096106\n",
      "Train Epoch: 1 [19200/50000 (38.400%)]\tLoss: 0.082505\n",
      "Train Epoch: 1 [28800/50000 (57.600%)]\tLoss: 0.072906\n",
      "Train Epoch: 1 [38400/50000 (76.800%)]\tLoss: 0.072139\n",
      "Train Epoch: 1 [48000/50000 (96.000%)]\tLoss: 0.056463\n",
      "Mean train loss on epoch 1 : 0.07765357266568267\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.358727, roc auc: 0.9601\n",
      "\n",
      "Loss 0.3587268954142928, did not improve from 0.2779768304899335 for 0 epochs\n",
      "we are in epoch 2\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 2 [0/50000 (0.000%)]\tLoss: 0.080632\n",
      "Train Epoch: 2 [9600/50000 (19.200%)]\tLoss: 0.048876\n",
      "Train Epoch: 2 [19200/50000 (38.400%)]\tLoss: 0.046957\n",
      "Train Epoch: 2 [28800/50000 (57.600%)]\tLoss: 0.039677\n",
      "Train Epoch: 2 [38400/50000 (76.800%)]\tLoss: 0.036951\n",
      "Train Epoch: 2 [48000/50000 (96.000%)]\tLoss: 0.033783\n",
      "Mean train loss on epoch 2 : 0.047812771912431336\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.362387, roc auc: 0.9668\n",
      "\n",
      "Loss 0.3623871607705951, did not improve from 0.2779768304899335 for 1 epochs\n",
      "we are in epoch 3\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 3 [0/50000 (0.000%)]\tLoss: 0.002954\n",
      "Train Epoch: 3 [9600/50000 (19.200%)]\tLoss: 0.028219\n",
      "Train Epoch: 3 [19200/50000 (38.400%)]\tLoss: 0.026072\n",
      "Train Epoch: 3 [28800/50000 (57.600%)]\tLoss: 0.026644\n",
      "Train Epoch: 3 [38400/50000 (76.800%)]\tLoss: 0.033072\n",
      "Train Epoch: 3 [48000/50000 (96.000%)]\tLoss: 0.022416\n",
      "Mean train loss on epoch 3 : 0.023229524717608002\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.422551, roc auc: 0.9676\n",
      "\n",
      "Loss 0.4225507366936654, did not improve from 0.2779768304899335 for 2 epochs\n",
      "we are in epoch 4\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 4 [0/50000 (0.000%)]\tLoss: 0.008544\n",
      "Train Epoch: 4 [9600/50000 (19.200%)]\tLoss: 0.020859\n",
      "Train Epoch: 4 [19200/50000 (38.400%)]\tLoss: 0.021567\n",
      "Train Epoch: 4 [28800/50000 (57.600%)]\tLoss: 0.026107\n",
      "Train Epoch: 4 [38400/50000 (76.800%)]\tLoss: 0.022742\n",
      "Train Epoch: 4 [48000/50000 (96.000%)]\tLoss: 0.020199\n",
      "Mean train loss on epoch 4 : 0.020003032896784134\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.382929, roc auc: 0.9674\n",
      "\n",
      "Loss 0.38292890414595604, did not improve from 0.2779768304899335 for 3 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 5\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 5 [0/50000 (0.000%)]\tLoss: 0.065385\n",
      "Train Epoch: 5 [9600/50000 (19.200%)]\tLoss: 0.094317\n",
      "Train Epoch: 5 [19200/50000 (38.400%)]\tLoss: 0.073924\n",
      "Train Epoch: 5 [28800/50000 (57.600%)]\tLoss: 0.059200\n",
      "Train Epoch: 5 [38400/50000 (76.800%)]\tLoss: 0.065470\n",
      "Train Epoch: 5 [48000/50000 (96.000%)]\tLoss: 0.052281\n",
      "Mean train loss on epoch 5 : 0.06842957069010784\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.319270, roc auc: 0.9668\n",
      "\n",
      "Loss 0.3192696198821068, did not improve from 0.2779768304899335 for 4 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 6\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 6 [0/50000 (0.000%)]\tLoss: 0.160238\n",
      "Train Epoch: 6 [9600/50000 (19.200%)]\tLoss: 0.088345\n",
      "Train Epoch: 6 [19200/50000 (38.400%)]\tLoss: 0.082699\n",
      "Train Epoch: 6 [28800/50000 (57.600%)]\tLoss: 0.066329\n",
      "Train Epoch: 6 [38400/50000 (76.800%)]\tLoss: 0.064368\n",
      "Train Epoch: 6 [48000/50000 (96.000%)]\tLoss: 0.056057\n",
      "Mean train loss on epoch 6 : 0.08633940464118495\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.285774, roc auc: 0.9685\n",
      "\n",
      "Loss 0.2857738006860018, did not improve from 0.2779768304899335 for 5 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 7\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 7 [0/50000 (0.000%)]\tLoss: 0.080369\n",
      "Train Epoch: 7 [9600/50000 (19.200%)]\tLoss: 0.083482\n",
      "Train Epoch: 7 [19200/50000 (38.400%)]\tLoss: 0.074889\n",
      "Train Epoch: 7 [28800/50000 (57.600%)]\tLoss: 0.070196\n",
      "Train Epoch: 7 [38400/50000 (76.800%)]\tLoss: 0.066319\n",
      "Train Epoch: 7 [48000/50000 (96.000%)]\tLoss: 0.065105\n",
      "Mean train loss on epoch 7 : 0.07339354760323961\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.283334, roc auc: 0.9669\n",
      "\n",
      "Loss 0.2833336496260017, did not improve from 0.2779768304899335 for 6 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 8\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 8 [0/50000 (0.000%)]\tLoss: 0.033850\n",
      "Train Epoch: 8 [9600/50000 (19.200%)]\tLoss: 0.098511\n",
      "Train Epoch: 8 [19200/50000 (38.400%)]\tLoss: 0.086076\n",
      "Train Epoch: 8 [28800/50000 (57.600%)]\tLoss: 0.076206\n",
      "Train Epoch: 8 [38400/50000 (76.800%)]\tLoss: 0.072822\n",
      "Train Epoch: 8 [48000/50000 (96.000%)]\tLoss: 0.067159\n",
      "Mean train loss on epoch 8 : 0.07243739631958306\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.250443, roc auc: 0.9691\n",
      "\n",
      "Test loss improved from 0.2779768304899335 to 0.25044341874308884, saving\n",
      "we are in epoch 9\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 9 [0/50000 (0.000%)]\tLoss: 0.018339\n",
      "Train Epoch: 9 [9600/50000 (19.200%)]\tLoss: 0.066559\n",
      "Train Epoch: 9 [19200/50000 (38.400%)]\tLoss: 0.066502\n",
      "Train Epoch: 9 [28800/50000 (57.600%)]\tLoss: 0.060893\n",
      "Train Epoch: 9 [38400/50000 (76.800%)]\tLoss: 0.059554\n",
      "Train Epoch: 9 [48000/50000 (96.000%)]\tLoss: 0.062305\n",
      "Mean train loss on epoch 9 : 0.055691881667201716\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.265703, roc auc: 0.9683\n",
      "\n",
      "Loss 0.26570282969623804, did not improve from 0.25044341874308884 for 0 epochs\n",
      "we are in epoch 10\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 10 [0/50000 (0.000%)]\tLoss: 0.040047\n",
      "Train Epoch: 10 [9600/50000 (19.200%)]\tLoss: 0.060033\n",
      "Train Epoch: 10 [19200/50000 (38.400%)]\tLoss: 0.051991\n",
      "Train Epoch: 10 [28800/50000 (57.600%)]\tLoss: 0.056608\n",
      "Train Epoch: 10 [38400/50000 (76.800%)]\tLoss: 0.051346\n",
      "Train Epoch: 10 [48000/50000 (96.000%)]\tLoss: 0.051446\n",
      "Mean train loss on epoch 10 : 0.05191160747936616\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.273827, roc auc: 0.9683\n",
      "\n",
      "Loss 0.27382721938192844, did not improve from 0.25044341874308884 for 1 epochs\n",
      "we are in epoch 11\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 11 [0/50000 (0.000%)]\tLoss: 0.070992\n",
      "Train Epoch: 11 [9600/50000 (19.200%)]\tLoss: 0.049135\n",
      "Train Epoch: 11 [19200/50000 (38.400%)]\tLoss: 0.048591\n",
      "Train Epoch: 11 [28800/50000 (57.600%)]\tLoss: 0.052378\n",
      "Train Epoch: 11 [38400/50000 (76.800%)]\tLoss: 0.047454\n",
      "Train Epoch: 11 [48000/50000 (96.000%)]\tLoss: 0.048255\n",
      "Mean train loss on epoch 11 : 0.05280073155959447\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.293567, roc auc: 0.9683\n",
      "\n",
      "Loss 0.29356671520508826, did not improve from 0.25044341874308884 for 2 epochs\n",
      "we are in epoch 12\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 12 [0/50000 (0.000%)]\tLoss: 0.038170\n",
      "Train Epoch: 12 [9600/50000 (19.200%)]\tLoss: 0.049389\n",
      "Train Epoch: 12 [19200/50000 (38.400%)]\tLoss: 0.043647\n",
      "Train Epoch: 12 [28800/50000 (57.600%)]\tLoss: 0.047240\n",
      "Train Epoch: 12 [38400/50000 (76.800%)]\tLoss: 0.045817\n",
      "Train Epoch: 12 [48000/50000 (96.000%)]\tLoss: 0.044406\n",
      "Mean train loss on epoch 12 : 0.04477814755635336\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.302306, roc auc: 0.9676\n",
      "\n",
      "Loss 0.30230568558909, did not improve from 0.25044341874308884 for 3 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 13\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 13 [0/50000 (0.000%)]\tLoss: 0.092307\n",
      "Train Epoch: 13 [9600/50000 (19.200%)]\tLoss: 0.068001\n",
      "Train Epoch: 13 [19200/50000 (38.400%)]\tLoss: 0.067207\n",
      "Train Epoch: 13 [28800/50000 (57.600%)]\tLoss: 0.068659\n",
      "Train Epoch: 13 [38400/50000 (76.800%)]\tLoss: 0.068538\n",
      "Train Epoch: 13 [48000/50000 (96.000%)]\tLoss: 0.063886\n",
      "Mean train loss on epoch 13 : 0.0714330367060999\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.258936, roc auc: 0.9686\n",
      "\n",
      "Loss 0.2589360948186368, did not improve from 0.25044341874308884 for 4 epochs\n",
      "Reducing LR by two and reloading best model\n",
      "we are in epoch 14\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 14 [0/50000 (0.000%)]\tLoss: 0.070009\n",
      "Train Epoch: 14 [9600/50000 (19.200%)]\tLoss: 0.069097\n",
      "Train Epoch: 14 [19200/50000 (38.400%)]\tLoss: 0.065120\n",
      "Train Epoch: 14 [28800/50000 (57.600%)]\tLoss: 0.070645\n",
      "Train Epoch: 14 [38400/50000 (76.800%)]\tLoss: 0.064851\n",
      "Train Epoch: 14 [48000/50000 (96.000%)]\tLoss: 0.068277\n",
      "Mean train loss on epoch 14 : 0.06799987275308618\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.249571, roc auc: 0.9695\n",
      "\n",
      "Test loss improved from 0.25044341874308884 to 0.24957066192291677, saving\n",
      "Training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.679297\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.566612\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.492556\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.495218\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.475937\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.477105\n",
      "Mean train loss on epoch 0 : 0.5311208716531596\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.416078, roc auc: 0.8917\n",
      "\n",
      "we are in epoch 0\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 0 [0/50000 (0.000%)]\tLoss: 0.446587\n",
      "Train Epoch: 0 [9600/50000 (19.200%)]\tLoss: 0.341768\n",
      "Train Epoch: 0 [19200/50000 (38.400%)]\tLoss: 0.228897\n",
      "Train Epoch: 0 [28800/50000 (57.600%)]\tLoss: 0.178419\n",
      "Train Epoch: 0 [38400/50000 (76.800%)]\tLoss: 0.154831\n",
      "Train Epoch: 0 [48000/50000 (96.000%)]\tLoss: 0.114991\n",
      "Mean train loss on epoch 0 : 0.2442487515571217\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.318981, roc auc: 0.9610\n",
      "\n",
      "Test loss improved from 100000.0 to 0.31898069474846125, saving\n",
      "we are in epoch 1\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 1 [0/50000 (0.000%)]\tLoss: 0.090906\n",
      "Train Epoch: 1 [9600/50000 (19.200%)]\tLoss: 0.103052\n",
      "Train Epoch: 1 [19200/50000 (38.400%)]\tLoss: 0.086399\n",
      "Train Epoch: 1 [28800/50000 (57.600%)]\tLoss: 0.077518\n",
      "Train Epoch: 1 [38400/50000 (76.800%)]\tLoss: 0.064213\n",
      "Train Epoch: 1 [48000/50000 (96.000%)]\tLoss: 0.063865\n",
      "Mean train loss on epoch 1 : 0.08099237957969307\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "OK!\n",
      "OK!\n",
      "\n",
      "Test set: Average loss: 0.278727, roc auc: 0.9784\n",
      "\n",
      "Test loss improved from 0.31898069474846125 to 0.2787269074469805, saving\n",
      "we are in epoch 2\n",
      "Setting DEVICE:\n",
      "\t MPS is available\n",
      "Train Epoch: 2 [0/50000 (0.000%)]\tLoss: 0.174773\n",
      "Train Epoch: 2 [9600/50000 (19.200%)]\tLoss: 0.051916\n",
      "Train Epoch: 2 [19200/50000 (38.400%)]\tLoss: 0.043308\n",
      "Train Epoch: 2 [28800/50000 (57.600%)]\tLoss: 0.045079\n",
      "Train Epoch: 2 [38400/50000 (76.800%)]\tLoss: 0.043374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# INIZIO DEL TRAINING\n",
    "samples_per_epoch = 50000 #define number of samples per epoch, since dataset is big\n",
    "# CICLO SUI GRUPPI DELLA C.V.\n",
    "for valid_idx in range(n_groups):\n",
    "\n",
    "    logfile =  model_dir+'/{}.fold{}.logfile.txt'.format(model_name, valid_idx)\n",
    "    best_w_path = model_dir+'/{}.fold{}.best.pt'.format(model_name, valid_idx)\n",
    "    es_w_path =  model_dir+'/{}.fold{}.es.pt'.format(model_name, valid_idx)\n",
    "    \n",
    "    \n",
    "    print('Training fold {}'.format(valid_idx))\n",
    "    \n",
    "    #with open(logfile, \"w\") as log:\n",
    "    #    pass    \n",
    "    \n",
    "    training_aug = aug_train() # FUNZIONE IN UTILS\n",
    "    validation_aug = aug_val() # FUNZIONE IN UTILS\n",
    "    \n",
    "    curr_lr = 3e-3#3e-4\n",
    "    \n",
    "    train_sampler = torch.utils.data.RandomSampler(DataGenerator(folds_id_val[valid_idx],       # GENERATES DATASET FOR LOADING\n",
    "                                                                 folds_label_val[valid_idx], \n",
    "                                                                 validation_aug, train_im_dir),\n",
    "                                                   replacement=True, \n",
    "                                                   num_samples=samples_per_epoch)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(DataGenerator(folds_id_train[valid_idx], \n",
    "                                                             folds_label_train[valid_idx], \n",
    "                                                             training_aug, train_im_dir),\n",
    "                                               pin_memory=False,\n",
    "                                               num_workers=4,\n",
    "                                               batch_size=b_size, \n",
    "                                               sampler=train_sampler)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(DataGenerator(folds_id_val[valid_idx], \n",
    "                                                       folds_label_val[valid_idx], \n",
    "                                                       validation_aug, train_im_dir),\n",
    "                                             pin_memory=False,\n",
    "                                             num_workers=1,\n",
    "                                             batch_size=b_size)\n",
    "    \n",
    "    # DEFINIAMO LA FUNZIONE DI LOSS - \n",
    "    loss_f = nn.BCELoss() # BINARY CROSS ENTROPY\n",
    "\n",
    "    best_score = 0\n",
    "    best_loss = 1e5\n",
    "    idx_stop = 0\n",
    "\n",
    "    ##############################################\n",
    "    # OK QUI BISOGNA LAVORARCI\n",
    "\n",
    "    # LOAD RESNET34 - PRETRAINED  # questo andrebbe sostituito cazzo!\n",
    "    base_model = pretrainedmodels.resnet34(num_classes=1000, \n",
    "                                           pretrained='imagenet').to(device) \n",
    "    \n",
    "    #model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Esempio di ResNet-18 preaddestrata\n",
    "\n",
    "    \n",
    "    # DEFINISCO IL MODEL! # OK QUI \n",
    "    model = Net(base_model, 512).to(device)\n",
    "\n",
    "    ##############################################\n",
    "    \n",
    "    # \"TRAINING WITH FROZEN LAYERS EXCEPT FOR CLASSIFICATION HEAD\"\n",
    "    # OK, ALCUNI LAYERS VENGONO BLOCCATI CON UN LEARNING RATE PARI A ZERO, PER CUI NON VENGONO RIADDESTRATI!\n",
    "    optimizer = optim.SGD([{'params': model.layer0.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer1.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer2.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer3.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer4.parameters(), 'lr': 0},\n",
    "                           {'params': model.classif.parameters()}], lr=0.05, momentum=0.9)\n",
    "    \n",
    "\n",
    "    \n",
    "    # QUI INIZIA GIà A TRAINARE, QUESTO è IL PRIMO GIRO, CHISSà PERCHè LO FA ESTERNO\n",
    "    # LAUNCH TRAIN, TEST AND WRITE LOG\n",
    "    train_loss = train(model= model,\n",
    "                           train_loader= train_loader, \n",
    "                           optimizer= optimizer, \n",
    "                           epoch= 0, \n",
    "                           log_interval= 100, \n",
    "                           loss_f= loss_f, \n",
    "                           samples_per_epoch= samples_per_epoch,\n",
    "                           scheduler= None)\n",
    "    \n",
    "    test_loss, score = test(model= model, \n",
    "                                test_loader= val_loader, \n",
    "                                loss_f= loss_f)\n",
    "    \n",
    "    write_log(logfile, train_loss, test_loss, score, lr = \"not available\")\n",
    "    \n",
    "    '''\n",
    "    start training the model with all layers\n",
    "    Training scheme : train while validation loss decreases, save model at each improvement of test loss. \n",
    "    if loss does not decreases for 3 epochs, reload last best model, reduce lr by factor of 2. \n",
    "    If loss still doesn't decrease for 10 epochs, stop the model. \n",
    "    '''\n",
    "    for epoch in range(15):\n",
    "        print(f'we are in epoch {epoch}')\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=curr_lr, max_lr=3*curr_lr, mode = 'triangular')\n",
    "        #scheduler = CyclicLR(optimizer, max_lr=3*curr_lr)\n",
    "\n",
    "        # LAUNCH TRAIN, TEST AND WRITE LOG\n",
    "        train_loss = train(model= model,\n",
    "                           train_loader= train_loader, \n",
    "                           optimizer= optimizer, \n",
    "                           epoch= epoch, \n",
    "                           log_interval= 100, \n",
    "                           loss_f= loss_f, \n",
    "                           samples_per_epoch= samples_per_epoch,\n",
    "                           scheduler= scheduler)\n",
    "        \n",
    "        test_loss, score = test(model= model, \n",
    "                                test_loader= val_loader, \n",
    "                                loss_f= loss_f)\n",
    "        \n",
    "        write_log(logfile, train_loss, test_loss, score, lr = curr_lr)\n",
    "        \n",
    "        if test_loss<best_loss:\n",
    "            print('Test loss improved from {} to {}, saving'.format(best_loss, test_loss))\n",
    "            best_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_w_path)\n",
    "            idx_stop = 0\n",
    "        else:\n",
    "            print('Loss {}, did not improve from {} for {} epochs'.format(test_loss, best_loss, idx_stop))\n",
    "            idx_stop += 1\n",
    "        if idx_stop>3:\n",
    "            print('Reducing LR by two and reloading best model')\n",
    "            model.load_state_dict(torch.load(best_w_path))\n",
    "            curr_lr = curr_lr/2\n",
    "        if idx_stop>10:\n",
    "            print('Stopping the model')\n",
    "            torch.save(model.state_dict(), es_w_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "DIR = './'\n",
    "train_im_dir = DIR+'/train'\n",
    "test_im_dir = DIR+'/test'\n",
    "\n",
    "model_dir = os.path.join(DIR,'resnet34')\n",
    "model_name = 'resnet34'\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(DIR,'train_labels.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\n",
    "patch_ids = pd.read_csv(os.path.join(DIR,'patch_id_wsi.csv'))\n",
    "train_data = pd.merge(train_data, patch_ids, on='id')\n",
    "\n",
    "n_groups = 15\n",
    "\n",
    "# CROSS VALIDATION OBJECT\n",
    "skf = GroupKFold(n_splits=n_groups)\n",
    "\n",
    "# CONTENITORI DEI FOLD DELLA CROSS-VALIDATION\n",
    "folds_id_train = []\n",
    "folds_label_train = []\n",
    "folds_id_val = []\n",
    "folds_label_val = []\n",
    "\n",
    "# POPOLANDO I CONTENITORI\n",
    "for train_index, test_index in skf.split(train_data['id'].values, train_data['label'].values, train_data['wsi'].values):\n",
    "    folds_id_train.append(train_data['id'].values[train_index])\n",
    "    folds_id_val.append(train_data['id'].values[test_index])\n",
    "    folds_label_train.append(train_data['label'].values[train_index])\n",
    "    folds_label_val.append(train_data['label'].values[test_index])\n",
    "\n",
    "# .....\n",
    "test_id = test_data['id'].values\n",
    "test_label = test_data['label'].values\n",
    "\n",
    "# CONTENGONO INFO SULLA CROSS-VALIDATION\n",
    "val_preds = []\n",
    "val_labels = []\n",
    "test_preds = []\n",
    "scores_CV = []\n",
    "\n",
    "# ESEGUE LA CROSS-VALIDATION\n",
    "for valid_idx in range(n_groups):\n",
    "    # IMPORT IL MODELLO BASE\n",
    "    base_model = pretrainedmodels.resnet34(num_classes=1000,pretrained='imagenet').to(device) #load pretrained as base\n",
    "    \n",
    "    # CREO IL MODELLO\n",
    "    model = Net(base_model, 512).to(device) # create model\n",
    "\n",
    "    # CARICO I PARAMETRI DEL MODELLO TRAINATO  \n",
    "    model.load_state_dict(torch.load(model_dir+'/resnet34.fold{}.best.pt'.format(valid_idx))) #loading weights\n",
    "    \n",
    "    # MODALITA' INFERENZA\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    valid_preds_idx = np.zeros((len(folds_id_val[valid_idx])))\n",
    "    valid_target_idx = np.zeros((len(folds_id_val[valid_idx])))\n",
    "    test_preds_idx = np.zeros((len(test_label)))\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(DataGenerator(folds_id_val[valid_idx], folds_label_val[valid_idx], validation_aug, train_im_dir), \n",
    "                                             shuffle=False, pin_memory=False, num_workers=1,batch_size=1)\n",
    "    test_loader = torch.utils.data.DataLoader(DataGenerator(test_id, test_label, validation_aug, test_im_dir), \n",
    "                                              shuffle=False, pin_memory=False, num_workers=1,batch_size=1)  \n",
    "    \n",
    "    #predction for validation data\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, target) in enumerate(tqdm_notebook(val_loader)):\n",
    "            #output = protein_model(x.to(device, dtype=torch.float))\n",
    "            image = np.rollaxis(x.numpy()[0], 0, 3)\n",
    "            images = make_tta_heavy(image,n_images=8) #create 8 images for random augmentations to take mean prediciton of each\n",
    "            output = model(torch.from_numpy(images).to(device, dtype=torch.float))\n",
    "            output = output.mean()\n",
    "            valid_preds_idx[batch_idx] = output\n",
    "            valid_target_idx[batch_idx] = target\n",
    "    \n",
    "    val_preds.append(valid_preds_idx)\n",
    "    val_labels.append(valid_target_idx)\n",
    "    \n",
    "    score_CV_idx = roc_auc_score(valid_target_idx, valid_preds_idx)\n",
    "    scores_CV.append(score_CV_idx)\n",
    "    \n",
    "    print('fold {}, score {}'.format(valid_idx, score_CV_idx))\n",
    "    \n",
    "    #predction for test data\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, target) in enumerate(tqdm_notebook(test_loader)):\n",
    "            image = np.rollaxis(x.numpy()[0], 0, 3)\n",
    "            images = make_tta_heavy(image,n_images=8) # TTA\n",
    "            output = model(torch.from_numpy(images).to(device, dtype=torch.float))\n",
    "            output = output.mean()            \n",
    "            #output = protein_model(x.to(device, dtype=torch.float))\n",
    "            test_preds_idx[batch_idx] = output\n",
    "    test_preds.append(test_preds_idx)    \n",
    "    \n",
    "    \n",
    "    \n",
    "val_preds_combined = np.hstack(val_preds)\n",
    "val_labels_combined = np.hstack(val_labels)\n",
    "#average test predctions over each fold\n",
    "test_preds_combined = np.vstack(test_preds)\n",
    "test_preds_combined = np.mean(test_preds_combined, axis=0)\n",
    "cv_rocauc = roc_auc_score(val_labels_combined, val_preds_combined)\n",
    "print('Total roc auc'.format(cv_rocauc))\n",
    "d = dict({'oof_preds':val_preds_combined,'oof_labels':val_labels_combined,'test_preds':test_preds_combined})\n",
    "with open(os.path.join(model_dir, \"resnet34.tta.Preds.pickle\"), \"wb\") as output_file:\n",
    "    pickle.dump(d, output_file)\n",
    "#create sample submission\n",
    "test_data['label'] = d['test_preds']\n",
    "test_data.to_csv(os.path.join(model_dir, 'resnet34.prediction.tta.csv') ,sep=',',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-networks-_F4AaA2c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
