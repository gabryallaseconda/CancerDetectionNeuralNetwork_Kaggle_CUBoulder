{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    130908\n",
       "1     89117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"histopathologic-cancer-detection/train_labels.csv\")\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.468945319074924"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "130908/89117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset has 220025 rows\n",
      "Splitted has in total 220025 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_dataframe(df:pd.DataFrame, num_of_splits:int) -> list[pd.DataFrame]:\n",
    "\n",
    "    # Shuffle the rows\n",
    "    df_shuffled = df.sample(frac=1, random_state=10) \n",
    "\n",
    "    rows_per_split = len(df_shuffled) // num_of_splits\n",
    "\n",
    "    dfs = [df_shuffled.iloc[i * rows_per_split:(i + 1) * rows_per_split] for i in range(num_of_splits)]\n",
    "\n",
    "    # Print to check line losses\n",
    "    print(f'Original dataset has {len(df)} rows')\n",
    "    print(f'Splitted has in total {sum([len(part) for part in dfs])} rows')\n",
    "\n",
    "    return dfs\n",
    "\n",
    "dfs = split_dataframe(df = df, num_of_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset has 220025 rows\n",
      "Splits has in total 220020 rows\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220020"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "#from torch.autograd import Variable\n",
    "#from torch.optim import Optimizer\n",
    "#from torch.utils import data\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "#import cv2\n",
    "from skimage.io import imread\n",
    "#from torch.utils.data.sampler import WeightedRandomSampler, BatchSampler\n",
    "#from tqdm import tqdm\n",
    "#from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold\n",
    "#import pretrainedmodels.utils as utils\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "from tools import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PER IMPOSTARE IL DEVICE\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('MPS is available')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No acceleration available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>wsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "      <td>camelyon16_train_normal_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "      <td>camelyon16_train_tumor_054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "      <td>camelyon16_train_tumor_008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "      <td>camelyon16_train_tumor_077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acfe80838488fae3c89bd21ade75be5c34e66be7</td>\n",
       "      <td>0</td>\n",
       "      <td>camelyon16_train_tumor_036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label  \\\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0   \n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1   \n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0   \n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0   \n",
       "4  acfe80838488fae3c89bd21ade75be5c34e66be7      0   \n",
       "\n",
       "                           wsi  \n",
       "0  camelyon16_train_normal_033  \n",
       "1   camelyon16_train_tumor_054  \n",
       "2   camelyon16_train_tumor_008  \n",
       "3   camelyon16_train_tumor_077  \n",
       "4   camelyon16_train_tumor_036  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# FOLDERS PATH\n",
    "DIR = 'study/Histopathologic-Cancer-Detection-master/' # './' #folder with train and test data\n",
    "train_im_dir = DIR+'/train'\n",
    "test_im_dir = DIR+'/test'\n",
    "\n",
    "# IMPORTING DATA\n",
    "train_data = pd.read_csv(os.path.join(DIR,'train_labels.csv')) #labels for train data\n",
    "patch_ids = pd.read_csv(os.path.join(DIR,'patch_id_wsi.csv')) #slides id for correct split \n",
    "# MERGIN DATASETS\n",
    "train_data = pd.merge(train_data, patch_ids, on='id')\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODELS\n",
    "model_dir = os.path.join(DIR, 'resnet34')\n",
    "model_name = 'resnet34'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_groups = 15 # number of folds # CROSS-VALIDATION PER VALIDAZIONE\n",
    "b_size = 96 # batch size\n",
    "\n",
    "# DEVICE\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# CROSS VALIDATION K-FOLD \n",
    "skf = GroupKFold(n_splits=n_groups)\n",
    "\n",
    "# CONTENITORI PER RACCOGLIERE I DATI DELLA CROSS-VALIDATION\n",
    "folds_id_train = []\n",
    "folds_label_train = []\n",
    "folds_id_val = []\n",
    "folds_label_val = []\n",
    "\n",
    "# RIEMPIO I CONTENITORI PER LA CROSS-VALIDATION\n",
    "for train_index, test_index in skf.split(train_data['id'].values, train_data['label'].values, train_data['wsi'].values):\n",
    "    folds_id_train.append(train_data['id'].values[train_index])\n",
    "    folds_id_val.append(train_data['id'].values[test_index])\n",
    "    folds_label_train.append(train_data['label'].values[train_index])\n",
    "    folds_label_val.append(train_data['label'].values[test_index])\n",
    "\n",
    "# INIZIO DEL TRAINING\n",
    "samples_per_epoch = 50000 #define number of samples per epoch, since dataset is big\n",
    "# CICLO SUI GRUPPI DELLA C.V.\n",
    "for valid_idx in range(n_groups):\n",
    "    logfile =  model_dir+'/{}.fold{}.logfile.txt'.format(model_name, valid_idx)\n",
    "    best_w_path = model_dir+'/{}.fold{}.best.pt'.format(model_name, valid_idx)\n",
    "    es_w_path =  model_dir+'/{}.fold{}.es.pt'.format(model_name, valid_idx)\n",
    "    print('Training fold {}'.format(valid_idx))\n",
    "    \n",
    "    with open(logfile, \"w\") as log:\n",
    "        pass    \n",
    "    \n",
    "    traing_aug = aug_train() # FUNZIONE IN UTILS\n",
    "    validation_aug = aug_val() # FUNZIONE IN UTILS\n",
    "    \n",
    "    curr_lr = 3e-4\n",
    "    \n",
    "    train_sampler = torch.utils.data.RandomSampler(DataGenerator(folds_id_val[valid_idx],       # GENERATES DATASET FOR LOADING\n",
    "                                                                 folds_label_val[valid_idx], \n",
    "                                                                 validation_aug, train_im_dir),\n",
    "                                                   replacement=True, \n",
    "                                                   num_samples=samples_per_epoch)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(DataGenerator(folds_id_train[valid_idx], \n",
    "                                                             folds_label_train[valid_idx], \n",
    "                                                             traing_aug, train_im_dir),\n",
    "                                               pin_memory=False,\n",
    "                                               num_workers=4,\n",
    "                                               batch_size=b_size, \n",
    "                                               sampler=train_sampler)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(DataGenerator(folds_id_val[valid_idx], \n",
    "                                                       folds_label_val[valid_idx], \n",
    "                                                       validation_aug, train_im_dir),\n",
    "                                             pin_memory=False,\n",
    "                                             num_workers=1,\n",
    "                                             batch_size=b_size)\n",
    "    \n",
    "    # DEFINIAMO LA FUNZIONE DI LOSS - \n",
    "    loss_f = nn.BCELoss() # BINARY CROSS ENTROPY\n",
    "\n",
    "    best_score = 0\n",
    "    best_loss = 1e5\n",
    "    idx_stop = 0\n",
    "\n",
    "    # LOAD RESNET34 - PRETRAINED\n",
    "    base_model = pretrainedmodels.resnet34(num_classes=1000, \n",
    "                                           pretrained='imagenet').to(device)\n",
    "    \n",
    "    # DEFINISCO IL MODEL!\n",
    "    model = Net(base_model, 512).to(device)\n",
    "    \n",
    "    # \"TRAINING WITH FROZEN LAYERS EXCEPT FOR CLASSIFICATION HEAD\"\n",
    "    optimizer = optim.SGD([{'params': model.layer0.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer1.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer2.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer3.parameters(), 'lr': 0},\n",
    "                           {'params': model.layer4.parameters(), 'lr': 0},\n",
    "                           {'params': model.classif.parameters()}], lr=0.05, momentum=0.9)\n",
    "    \n",
    "    # LAUNCH TRAIN, TEST AND WRITE LOG\n",
    "    train_loss = train(model, train_loader, optimizer, 0, 100, loss_f, samples_per_epoch, device)\n",
    "    test_loss, score = test(model, val_loader, loss_f, 0, device)\n",
    "    write_log(logfile, train_loss, test_loss, score, lr = \"not available\")\n",
    "    \n",
    "    '''\n",
    "    start training the model with all layers\n",
    "    Training scheme : train while validation loss decreases, save model at each improvement of test loss. \n",
    "    if loss does not decreases for 3 epochs, reload last best model, reduce lr by factor of 2. \n",
    "    If loss still doesn't decrease for 10 epochs, stop the model. \n",
    "    '''\n",
    "    for epoch in range(50):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=curr_lr, momentum=0.9)\n",
    "        scheduler = CyclicLR(optimizer, max_lr=3*curr_lr)\n",
    "\n",
    "        # LAUNCH TRAIN, TEST AND WRITE LOG\n",
    "        train_loss = train(model, train_loader, optimizer, epoch, 100, loss_f, samples_per_epoch)\n",
    "        test_loss, score = test(model, val_loader, loss_f, epoch)\n",
    "        write_log(logfile, train_loss, test_loss, score)\n",
    "        \n",
    "        if test_loss<best_loss:\n",
    "            print('Test loss improved from {} to {}, saving'.format(best_loss, test_loss))\n",
    "            best_loss = test_loss\n",
    "            torch.save(model.state_dict(), best_w_path)\n",
    "            idx_stop = 0\n",
    "        else:\n",
    "            print('Loss {}, did not improve from {} for {} epochs'.format(test_loss, best_loss, idx_stop))\n",
    "            idx_stop += 1\n",
    "        if idx_stop>3:\n",
    "            print('Reducing LR by two and reloading best model')\n",
    "            model.load_state_dict(torch.load(best_w_path))\n",
    "            curr_lr = curr_lr/2\n",
    "        if idx_stop>10:\n",
    "            print('Stopping the model')\n",
    "            torch.save(model.state_dict(), es_w_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-networks-_F4AaA2c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
