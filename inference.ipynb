{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Get predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting DEVICE:\n",
      "\t MPS is available\n"
     ]
    }
   ],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing label dataset\n",
    "\n",
    "To run the full crossvalidation, remove .head(30000). This will multiply about by 20 the time required by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOLDERS PATH\n",
    "source_dir = 'histopathologic-cancer-detection/'\n",
    "test_im_source_dir = source_dir+'/test'\n",
    "\n",
    "# IMPORTING DATA\n",
    "test_data = pd.read_csv(os.path.join(source_dir,'sample_submission.csv')) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = list(test_data.id)\n",
    "#data_labels = list(test_data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_source_dir = 'trained_model/'\n",
    "model_name = 'final'\n",
    "\n",
    "model_path =  model_source_dir+'/{}.model.pt'.format(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gabrielegabrielli/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pretrained model\n",
    "base_model = pretrainedmodels.resnet34(num_classes=1000, \n",
    "                                    pretrained='imagenet').to(device) \n",
    "    \n",
    "# Shape the model    \n",
    "model = Net(base_model, 512).to(device)\n",
    "\n",
    "# Load model from saved \n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielegabrielli/Documents/NN/Kaggle_CancerDetection/tools.py:320: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image =  torch.tensor(image, dtype = torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 96, 96])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#image = np.rollaxis(x.numpy()[0], 0, 3)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m image \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 23\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mproduce_test_time_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m output \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(images)\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[1;32m     26\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mmean()            \n",
      "File \u001b[0;32m~/Documents/NN/Kaggle_CancerDetection/tools.py:348\u001b[0m, in \u001b[0;36mproduce_test_time_augmentation\u001b[0;34m(image, number)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# Others\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, number):\n\u001b[0;32m--> 348\u001b[0m     images[i] \u001b[38;5;241m=\u001b[39m \u001b[43maugmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# Switch axis\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmoveaxis(images, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/albumentations/core/composition.py:195\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to pass data to augmentations as named arguments, for example: aug(image=image)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_check_args:\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(force_apply, (\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_apply must have bool or int type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m need_to_run \u001b[38;5;241m=\u001b[39m force_apply \u001b[38;5;129;01mor\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/neural-networks-_F4AaA2c-py3.10/lib/python3.10/site-packages/albumentations/core/composition.py:275\u001b[0m, in \u001b[0;36mCompose._check_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_data_name \u001b[38;5;129;01min\u001b[39;00m checked_single:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m must be numpy array type\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_name))\n\u001b[1;32m    276\u001b[0m     shapes\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_data_name \u001b[38;5;129;01min\u001b[39;00m checked_multi:\n",
      "\u001b[0;31mTypeError\u001b[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(DataGeneratorInference(\n",
    "                                                data_ids, \n",
    "                                                test_im_source_dir), \n",
    "                                            shuffle=False, \n",
    "                                            pin_memory=False, \n",
    "                                            num_workers=1,\n",
    "                                            batch_size=1) \n",
    "\n",
    "model.eval() \n",
    "\n",
    "predictions = []\n",
    "batch_prediction = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, x in enumerate(test_loader):\n",
    "        # Test time augmentation\n",
    "\n",
    "        \n",
    "\n",
    "        image = np.rollaxis(x.numpy()[0], 0, 3)\n",
    "\n",
    "        print(image.shape)\n",
    "\n",
    "        images = produce_test_time_augmentation(image,number=8)\n",
    "        \n",
    "        output = model(torch.from_numpy(images).to(device, dtype=torch.float))\n",
    "        output = output.mean()            \n",
    "        #output = protein_model(x.to(device, dtype=torch.float))\n",
    "        batch_prediction[batch_idx] = output\n",
    "    \n",
    "    predictions.append(batch_prediction)    \n",
    "    \n",
    "    \n",
    "\n",
    "predictions = np.vstack(predictions) # get together the batches (one batch contains tta of one image)\n",
    "predictions = np.mean(predictions, axis=0) # mean of tta of one image\n",
    "\n",
    "\n",
    "test_data['label'] = predictions\n",
    "\n",
    "test_data.to_cvs('predictions.csv', sep =',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-networks-_F4AaA2c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
